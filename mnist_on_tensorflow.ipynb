{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_on_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VansYeh/TensorFlow/blob/master/mnist_on_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVB59SAdb3rl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5cb73be-0ba4-4885-d3b4-36023934dcaa"
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLkR2Ghub7Vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append(r'/content/drive/My Drive/Colab Notebooks/mnist_data/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI8nQkgmkwSU",
        "colab_type": "code",
        "outputId": "9d8b71c8-1fc5-4cf4-b22b-e8e4598a6ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from load_mnist import load_mnist as mnist\n",
        "\n",
        "#load mnist to (x_train, y_train), (x_test, y_test)\n",
        "mnist_train=r'/content/drive/My Drive/Colab Notebooks/mnist_data/mnist_train.csv'\n",
        "mnist_test=r'./sample_data/mnist_test.csv'\n",
        "\n",
        "\n",
        "a = mnist(mnist_train, mnist_test)\n",
        "(x_train, y_train), (x_test, y_test) = a.load_mnist(one_hot_label=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading csv file...\n",
            "File /content/drive/My Drive/Colab Notebooks/mnist_data/mnist_train.csv load finish...\n",
            "File ./sample_data/mnist_test.csv load finish...\n",
            "transfor to np.ndarray START...\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31xWw-FUlbRY",
        "colab_type": "text"
      },
      "source": [
        "#Check mnist data if it has been loaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6cVGGC0k89z",
        "colab_type": "code",
        "outputId": "5f68481c-c330-4078-e221-4b1be1e2ee20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2e_lG1laeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "batch_size=100\n",
        "learning_rate = 0.8\n",
        "learning_rate_decay=0.999\n",
        "max_step=10000\n",
        "\n",
        "#initial train steps for record train times\n",
        "training_step = tf.Variable(0, trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmoQjTv8TShw",
        "colab_type": "text"
      },
      "source": [
        "## 準備訓練數據集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osI00k69TR1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a.setBatchSize(batch_size)\n",
        "x_validation, y_validation = a.get_next_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0vcfMrwuBYD",
        "colab_type": "text"
      },
      "source": [
        "## 定義得到的隱藏層和輸出層向前傳播的計算方式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hugvyf3_t9sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hidden_layer(x, w1,b1,w2,b2,layer_name):\n",
        "    layer1 = tf.nn.relu(tf.matmul(x,w1)+b1)\n",
        "    layer2 = tf.matmul(layer1,w2)+b2\n",
        "    return layer2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw3e3x2rwlOZ",
        "colab_type": "text"
      },
      "source": [
        "## 定義引層 weight 和 bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY2vIsC9vCjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, (None, 784), name='input')\n",
        "y_ = tf.placeholder(tf.float32, (None, 10), name='answer')\n",
        "\n",
        "w1 = tf.Variable(tf.truncated_normal((784,500), stddev=0.1))\n",
        "b1 = tf.Variable(tf.constant(0.1,shape=[500]))\n",
        "w2 = tf.Variable(tf.truncated_normal((500,10), stddev=0.1))\n",
        "b2 = tf.Variable(tf.constant(0.1,shape=[10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tZgqw6lyRlh",
        "colab_type": "text"
      },
      "source": [
        "## 定義 y 向前傳播的方式，可以透過 sess.run(y) 得到分類結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAc56cz3wSVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = hidden_layer(x, w1,b1,w2,b2,layer_name='y_query') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un1aSF4GygxC",
        "colab_type": "text"
      },
      "source": [
        "## 初始化滑動平均類，用來取得 weight & bias 每個 batch 訓練的平均\n",
        "## 其中設置 weight 和 bias 的衰減率 MAX: 0.99\n",
        "## 最後用滑動平均的輸出預測 輸入，***可能*** 會表現更好"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S--Ecah5yg8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "490e777f-c33f-448a-f48d-6f28827a829a"
      },
      "source": [
        "average_class = tf.train.ExponentialMovingAverage(0.99, training_step)\n",
        "\n",
        "#定義一個更新變量滑動平均值得操作需要向滑動平均的類 apply() 函數提供 data list\n",
        "#train_variables() 會返回所有 trainable 的 Variable(Graph.TRAINABLE_VARIABLES 中的數據)\n",
        "avg_op = average_class.apply(tf.trainable_variables())\n",
        "\n",
        "#用 1 個 batch data 計算 y，並得到滑動平均的輸出\n",
        "avg_y = hidden_layer(x, average_class.average(w1),average_class.average(b1),average_class.average(w2),average_class.average(b2),layer_name='avg_y') "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0704 07:50:17.828424 139716559660928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJUKpZr4-36u",
        "colab_type": "text"
      },
      "source": [
        "## 使用 sparse_softmax_cross_entropy_with_logits 為 交叉熵函數 計算 loss，可以針對單分類問題使用，像是手寫數字一般圖片裡面只有一個數字\n",
        "\n",
        "> Measures the probability error in discrete classification tasks in which the classes are mutually exclusive (each entry is in exactly one class). For example, each CIFAR-10 image is labeled with one and only one label: an image can be a dog or a truck, but not both.\n",
        "\n",
        "\n",
        "## 這邊還多加上了 正則化 L2 Function\n",
        "\n",
        "> 正則化常用來降低 Noise 對模型的影響， 在總損失函數中：L(w)，通常搭配使用: \n",
        "> L(w) = J(w) + r * R(w)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOdjSgnY84Df",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ba1e1e1b-63c9-4685-85f6-4329092f4c91"
      },
      "source": [
        "cross_rentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_,1))\n",
        "\n",
        "regularizer = tf.contrib.layers.l2_regularizer(0.0001)\n",
        "regularization = regularizer(w1)+regularizer(w2)\n",
        "loss = tf.reduce_mean(cross_rentropy) + regularization\n",
        "\n",
        "#指數衰減法 設置 learning rate\n",
        "le_rate = tf.train.exponential_decay(learning_rate, training_step, x_train.shape[0]/batch_size, learning_rate_decay)\n",
        "\n",
        "#使用梯度下降優化損失函數 L(w)\n",
        "trainer = tf.train.GradientDescentOptimizer(le_rate).minimize(loss, global_step=training_step)\n",
        "\n",
        "# tf.control_dependencies() 设计是用来控制计算流图的，给图中的某些计算指定顺序\n",
        "with tf.control_dependencies([trainer, avg_op]):\n",
        "    train_op = tf.no_op(name='train')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0704 07:50:20.519971 139716559660928 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIdWk6OcBo_T",
        "colab_type": "text"
      },
      "source": [
        "## 最後要印出正確率"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKwz0t4jBn3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crorent_predicition = tf.equal(tf.argmax(avg_y, 1), tf.argmax(y_, 1))\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(crorent_predicition, tf.float32))\n",
        "\n",
        "sess = tf.Session()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFWNC-RUmXln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###mv '/content/drive/My Drive/Colab Notebooks/mnist_data/load_mnist (2).py' '/content/drive/My Drive/Colab Notebooks/mnist_data/load_mnist.py'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZREF_aaQC_N5",
        "colab_type": "text"
      },
      "source": [
        "##用一個 Session 來 Run 吧"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnT0tKXKC-Aq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9fd7ce26-c85b-40a7-9caf-e7f4c8e903bc"
      },
      "source": [
        "#with sess:\n",
        "initializer = tf.global_variables_initializer()\n",
        "sess.run(initializer)\n",
        "\n",
        "validate_feed = {x: x_validation ,y_: y_validation}\n",
        "\n",
        "test_feed = {x:x_test,y_:y_test}\n",
        "\n",
        "for i in range(max_step):\n",
        "    if i%1000 == 0:\n",
        "        validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
        "        print('After %d training step(s), validation accuracy using avg model: %d%%'%(i, validate_acc*100))\n",
        "        pass\n",
        "\n",
        "    x_train_batch, y_train_batch = a.get_next_batch()            \n",
        "\n",
        "    #using all data train\n",
        "    sess.run(train_op, feed_dict={x: x_train_batch, y_: y_train_batch})\n",
        "    pass\n",
        "\n",
        "test_accu = sess.run(accuracy, feed_dict=test_feed)\n",
        "print('After %d training step(s), validation accuracy using avg model: %d%%'%(max_step, validate_acc*100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 0 training step(s), validation accuracy using avg model: 5%\n",
            "After 1000 training step(s), validation accuracy using avg model: 97%\n",
            "After 2000 training step(s), validation accuracy using avg model: 99%\n",
            "After 3000 training step(s), validation accuracy using avg model: 100%\n",
            "After 4000 training step(s), validation accuracy using avg model: 100%\n",
            "After 5000 training step(s), validation accuracy using avg model: 100%\n",
            "After 6000 training step(s), validation accuracy using avg model: 100%\n",
            "After 7000 training step(s), validation accuracy using avg model: 100%\n",
            "After 8000 training step(s), validation accuracy using avg model: 100%\n",
            "After 9000 training step(s), validation accuracy using avg model: 100%\n",
            "After 10000 training step(s), validation accuracy using avg model: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}